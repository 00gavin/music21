{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User's Guide, Chapter 13: More Music21Object Attributes and Properties\n",
    "\n",
    "At this point you know how to find a `Music21Object`, how to name them and group them (with `.id` and `.groups`) and how to position them in Streams (with `.offset`, `.priority`, `.classSortOrder` and the `.activeSite`). This section gets first into some more advanced things that Music21Objects have, then some more fun things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sites and the storing of elements\n",
    "\n",
    "All `Music21Objects` (i.e., elements) have a `.sites` property which is a :class:`~music21.sites.Sites` object which holds information about all the places the `Music21Object` is stored in. At its simplest, it's something that can be iterated over:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.stream.Stream s1> 10.0\n",
      "<music21.stream.Stream s2> 20.0\n"
     ]
    }
   ],
   "source": [
    "n = note.Note()\n",
    "s1 = stream.Stream(id='s1')\n",
    "s2 = stream.Stream(id='s2')\n",
    "s1.insert(10, n)\n",
    "s2.insert(20, n)\n",
    "\n",
    "for s in n.sites:\n",
    "    print(s, s.elementOffset(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the order of the Streams in `.sites` is guaranteed to be the order in which the note was inserted into the site.\n",
    "\n",
    "There's a lot more that `.sites` can do, but primarily for developers.  We will get back to sites later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivations\n",
    "\n",
    "We will talk about derivations more in a future chapter, butwe alluded to them in the Example in chapter 10, so let's say a few words about this advanced feature. A :class:`~music21.derivation.Derivation` object is a pointer to an object that this object is derived from in some way.  They've gone their separate ways to an extent, but may want to talk to each other later.  A `Music21Object` starts out with no useful Derivation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Derivation of <music21.note.Note C> from None via \"None\">"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = note.Note(\"C4\")\n",
    "c.derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can create new notes from it and they're not totally connected, but show their connection through `.derivation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.note.Note F>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = c.transpose('P4')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Derivation of <music21.note.Note F> from <music21.note.Note C> via \"transpose\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `c` has a life of its own from `f`.  We can add a sharp to C and the transpose relationship of F to C does not affect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<music21.note.Note C#>, <music21.note.Note F>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.pitch.accidental = pitch.Accidental('sharp')\n",
    "(c, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if `f` wants to do something to `c`, it can by changing itself and every element of its `.derivation.chain()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('diamond', 'diamond')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.notehead = 'diamond'\n",
    "for n in f.derivation.chain():\n",
    "    n.notehead = 'diamond'\n",
    "\n",
    "(f.notehead, c.notehead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While `f` can search upwards in its `.derivation.chain()` and find `c`, `c` cannot find `f` in its derivation; it is a connection that is designed to be one-way only.\n",
    "\n",
    "Setting derivations can be done manually, but it's an advanced enough topic that we will get to it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context attributes\n",
    "\n",
    "Several attributes of `Music21Objects` only work after the object has been placed inside a Stream that has certain features of their own.\n",
    "\n",
    "An easy one to understand is `.measureNumber` which finds the `.number` value of the measure that an object is placed in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = note.Note('C')\n",
    "m = stream.Measure()\n",
    "m.number = 7\n",
    "m.append(n)\n",
    "n.measureNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works even if a note is inside a voice inside a measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = stream.Voice()\n",
    "n2 = note.Note('D')\n",
    "v.append(n2)\n",
    "m.insert(0, v)\n",
    "n2.measureNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without a context, you'll get None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n3 = note.Note()\n",
    "n3.measureNumber is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second context attribute is, appropriately, called `.seconds`.  It requires a tempo.MetronomeMark() to be placed into the Stream before the object and will calculate how many seconds the object (note, etc.) lasts at that tempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.5\n"
     ]
    }
   ],
   "source": [
    "m.insert(0, tempo.MetronomeMark('Allegro', 120))\n",
    "print (n.quarterLength, n.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike `.measureNumber` and the rest of the attributes we will see below, you can change `.seconds` to reflect exact timing you might have from audio or MIDI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.seconds = 0.6\n",
    "n.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object with no tempo information in its surrounding context returns an error for `.seconds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Music21ObjectException",
     "evalue": "this object does not have a TempoIndication in Sites",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMusic21ObjectException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0a7112d868b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'E'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/cuthbert/git/music21base/music21/base.py\u001b[0m in \u001b[0;36m_getSeconds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3262\u001b[0m         \u001b[0mti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetContextByClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TempoIndication'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mti\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3264\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMusic21ObjectException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this object does not have a TempoIndication in Sites'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3265\u001b[0m         \u001b[0mmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSoundingMetronomeMark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m         \u001b[0;31m# once we have mm, simply pass in this duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMusic21ObjectException\u001b[0m: this object does not have a TempoIndication in Sites"
     ]
    }
   ],
   "source": [
    "n3 = note.Note('E')\n",
    "n3.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So use `try...except...` to catch this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for el in (n, n2, n3):\n",
    "    seconds = \"No information\"\n",
    "    try:\n",
    "        seconds = el.seconds\n",
    "    except exceptions21.Music21Exception:\n",
    "        pass\n",
    "    print(el.step, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "sphinx_links": {
     "any": true
    }
   },
   "source": [
    "The last three context attributes, `.beat`, `.beatStr` (beat string), and `.beatStrength`, all require :class:`~music21.meter.TimeSignature` contexts. Since they're the topic of :ref:`our next chapter<usersGuide_14_timeSignatures>` we'll put them off until then.\n",
    "\n",
    "Most `Music21Objects` such as `Notes` have many additional attributes, but these are all the ones that are common to every object that can go in a `Stream` (after all, what would `.step` mean for a :class:`~music21.tempo.MetronomeMark`?)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "..note::\n",
    "\n",
    "   You may find other attributes on your base.Music21Object, especially if you are running\n",
    "   an older version of `music21`. They are all deprecated and most have been removed in\n",
    "   v.3; programmers are advised to stick to the safe list of attributes described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods on `Music21Objects`\n",
    "\n",
    "Attributes and properties are aspects of an object that are lightweight and have no configuration options, so they are accessed without `()`. Methods tend to do more work and have more options, so they will always be called with `()` signs.\n",
    "\n",
    "Unlike attributes, where we have documented all of them, only a subset of the methods on `Music21Objects` are listed below.  All of them can be found in the documentation to :class:`~music21.base.Music21Object`, but many of them have obscure uses and might be moved later to not clutter up what is really important!  And those are..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .getOffsetBySite and .setOffsetBySite\n",
    "\n",
    "These methods work as the `.offset` attribute but can work on any site where the object is a part of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = note.Note()\n",
    "s1 = stream.Stream(id=\"s1\")\n",
    "s1.insert(10, n)\n",
    "s2 = stream.Stream(id=\"s2\")\n",
    "s2.insert(20, n)\n",
    "n.getOffsetBySite(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.setOffsetBySite(s1, 15.0)\n",
    "n.getOffsetBySite(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one extra possible attribute on `.getOffsetBySite`, \"stringReturns=True\" which will say whether or not an element has a shifting offset.  Right barlines have one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = stream.Measure()\n",
    "n3 = note.Note(type='whole')\n",
    "s3.append(n3)\n",
    "rb = bar.Barline()\n",
    "s3.rightBarline = rb\n",
    "rb.getOffsetBySite(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'highestTime'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.getOffsetBySite(s3, stringReturns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in fact if we change the duration of `n3` the position of the barline will shift along with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n3.duration.type = 'half'\n",
    "rb.getOffsetBySite(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getContextByClass()\n",
    "\n",
    "This is an extremely powerful tool -- you might not use it often, but be assured that `music21` is using it on your behalf all the time when sophisticated analysis is involved.  It finds the active element matching a certain class preceeding the element.  Let me demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.note.Note F#>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bach = corpus.parse('bwv66.6')\n",
    "lastNote = bach.recurse().getElementsByClass('Note')[-1]\n",
    "lastNote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What part is it in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.stream.Part Bass>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastNote.getContextByClass('Part')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the KeySignature at that moment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.key.KeySignature of 3 sharps, mode minor>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastNote.getContextByClass('KeySignature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the TimeSignature at that moment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<music21.meter.TimeSignature 4/4>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastNote.getContextByClass('TimeSignature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this such a sophisticated method? It knows about the differences in different types of Streams.  If the key signature changes in a different part then it doesn't affect the notes of the current part, but if it changes in a previous measure in the same part, then that matters.  Furthermore, the caching mechanism via something called `Timespans` is amazingly fast, so that running through an entire score getting the context for each object doesn't take long at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.meter.TimeSignature 6/8> 1\n",
      "<music21.meter.TimeSignature 2/4> 28\n",
      "<music21.meter.TimeSignature 6/8> 80\n",
      "<music21.meter.TimeSignature 3/4> 110\n"
     ]
    }
   ],
   "source": [
    "gloria = corpus.parse('luca/gloria')\n",
    "soprano = gloria.parts[0]\n",
    "\n",
    "lastTimeSignature = None\n",
    "for n in soprano.recurse().getElementsByClass('Note'):\n",
    "    thisTimeSignature = n.getContextByClass('TimeSignature')\n",
    "    if thisTimeSignature is not lastTimeSignature:\n",
    "        lastTimeSignature = thisTimeSignature\n",
    "        print(thisTimeSignature, n.measureNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might expect, the `.measureNumber` routine uses `.getContextByClass('Measure')` internally. What is also interesting is that `.getContextByClass` is smart enough to search out derivation chains to find what it is looking for.  For instance, this flat stream has only notes, no time signatures.  But it can still find each note's time signature ane measure number context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.meter.TimeSignature 6/8> 1\n",
      "<music21.meter.TimeSignature 2/4> 28\n",
      "<music21.meter.TimeSignature 6/8> 80\n",
      "<music21.meter.TimeSignature 3/4> 110\n"
     ]
    }
   ],
   "source": [
    "sfn = soprano.flat.notes.stream()\n",
    "\n",
    "lastTimeSignature = None\n",
    "for n in sfn:\n",
    "    thisTimeSignature = n.getContextByClass('TimeSignature')\n",
    "    if thisTimeSignature is not lastTimeSignature:\n",
    "        lastTimeSignature = thisTimeSignature\n",
    "        print(thisTimeSignature, n.measureNumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally `.getContextByClass` uses another `Music21Object` method called `.contextSites()` which is a generator that tells the system where to search next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<music21.stream.Measure 9 offset=33.0>, 2.0, 'elementsFirst')\n",
      "(<music21.stream.Part Bass>, 35.0, 'flatten')\n",
      "(<music21.stream.Score 0x106be5550>, 35.0, 'elementsOnly')\n"
     ]
    }
   ],
   "source": [
    "for cs in lastNote.contextSites():\n",
    "    print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says that first the elements of Measure 9 should be searched, beginning at 2.0 and working backwards to the beginning of the measure, then if the matching context isn't found, the measure will be flattened (in case there are other voices in the measure) and anything from before offset 2.0 of that flattened stream will be searched.\n",
    "\n",
    "If that fails, then the Bass part as a whole will be searched, with all elements flattened, beginning at offset 35 and working backwards.  That way if the context is in another measure it will be found.\n",
    "\n",
    "Then if that fails, it will look at the score as a whole, beginning at offset 35 and working backwards, but only looking at things that are at the score level, not looking at elements within other parts. There may be scores where for instance, expressive markings appear at the Score level. This will find them.\n",
    "\n",
    "Related to `.getContextByClass()` is `.getAllContextsByClass()` which is a generator that returns each preceeding context."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "..note::\n",
    "\n",
    "   Prior to v.3, `.getAllContextsByClass()` had a different purpose, so do not use it for\n",
    "   for this purpose. It was unreliable.\n",
    "   \n",
    "   Two known bugs that we hope to get fixed soon: if there are two or more\n",
    "   contexts at the same offset, `.getAllContextsByClass()` will skip over \n",
    "   all but one of them. Using `Music21Object` as a class list can create infinite loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<music21.meter.TimeSignature 3/4> 110\n",
      "<music21.meter.TimeSignature 6/8> 80\n",
      "<music21.meter.TimeSignature 2/4> 28\n",
      "<music21.meter.TimeSignature 6/8> 1\n"
     ]
    }
   ],
   "source": [
    "lastGloriaNote = sfn[-1]\n",
    "\n",
    "for ts in lastGloriaNote.getAllContextsByClass('TimeSignature'):\n",
    "    print(ts, ts.measureNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
